{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle wandb onnx -Uq\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xc_xtTn6ECN",
        "outputId": "6b7e997f-a098-4cdb-cf8e-c0bb5081ee70"
      },
      "id": "0xc_xtTn6ECN",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/17.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/17.6 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/17.6 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m15.5/17.6 MB\u001b[0m \u001b[31m247.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m265.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m141.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/Kaggle_credentials/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "3Q92W4PQ6EaA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae7cfcb1-1e62-4bb2-e1d0-051ef47e86cf"
      },
      "id": "3Q92W4PQ6EaA",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c walmart-recruiting-store-sales-forecasting\n",
        "! unzip /content/walmart-recruiting-store-sales-forecasting.zip\n",
        "! unzip /content/train.csv.zip\n",
        "! unzip /content/test.csv.zip\n",
        "! unzip /content/features.csv.zip\n",
        "! unzip /content/sampleSubmission.csv.zip"
      ],
      "metadata": {
        "id": "MPwqMv2z6H6S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4830dba7-db8f-4fd0-d0ab-55689b5ec4a6"
      },
      "id": "MPwqMv2z6H6S",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading walmart-recruiting-store-sales-forecasting.zip to /content\n",
            "\r  0% 0.00/2.70M [00:00<?, ?B/s]\n",
            "\r100% 2.70M/2.70M [00:00<00:00, 1.54GB/s]\n",
            "Archive:  /content/walmart-recruiting-store-sales-forecasting.zip\n",
            "  inflating: features.csv.zip        \n",
            "  inflating: sampleSubmission.csv.zip  \n",
            "  inflating: stores.csv              \n",
            "  inflating: test.csv.zip            \n",
            "  inflating: train.csv.zip           \n",
            "Archive:  /content/train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  /content/test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  /content/features.csv.zip\n",
            "  inflating: features.csv            \n",
            "Archive:  /content/sampleSubmission.csv.zip\n",
            "  inflating: sampleSubmission.csv    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install wandb -qU\n",
        "# !pip uninstall -y pmdarima numpy scipy statsmodels\n",
        "# !pip install numpy==1.24.4 scipy==1.10.1 statsmodels==0.13.5 pmdarima==2.0.3"
      ],
      "metadata": {
        "id": "myvAj7pC7CyH"
      },
      "id": "myvAj7pC7CyH",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import random\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "c5Vm5Z5I7DRW"
      },
      "id": "c5Vm5Z5I7DRW",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wandb\n",
        "import dill\n",
        "import logging\n",
        "from datetime import datetime, timedelta\n",
        "from prophet import Prophet\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings and logging\n",
        "warnings.filterwarnings('ignore')\n",
        "logging.getLogger('prophet').setLevel(logging.ERROR)\n",
        "logging.getLogger('cmdstanpy').setLevel(logging.ERROR)\n",
        "\n",
        "# WandB setup\n",
        "wandb.init(project=\"walmart-sales-forecasting\", name=\"Prophet_TimeSeries_Optimized\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "4B45831Qriot",
        "outputId": "146fce69-1504-4725-85c8-99ca4626696a"
      },
      "id": "4B45831Qriot",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdshan21\u001b[0m (\u001b[33mdshan21-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250731_200326-wh7gqtn4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting/runs/wh7gqtn4' target=\"_blank\">Prophet_TimeSeries_Optimized</a></strong> to <a href='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting/runs/wh7gqtn4' target=\"_blank\">https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting/runs/wh7gqtn4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting/runs/wh7gqtn4?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7a7cd2537e50>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Block 1: Data Loading and Initial Setup\n",
        "# =============================================================================\n",
        "\n",
        "print(\"Loading data...\")\n",
        "train_df = pd.read_csv(\"/content/train.csv\")\n",
        "features_df = pd.read_csv(\"/content/features.csv\")\n",
        "stores_df = pd.read_csv(\"/content/stores.csv\")\n",
        "test_df = pd.read_csv(\"/content/test.csv\")\n",
        "sample_submission = pd.read_csv(\"/content/sampleSubmission.csv\")\n",
        "\n",
        "# Convert dates\n",
        "train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
        "test_df['Date'] = pd.to_datetime(test_df['Date'])\n",
        "features_df['Date'] = pd.to_datetime(features_df['Date'])\n",
        "\n",
        "print(f\"Data loaded: Train {train_df.shape}, Test {test_df.shape}\")\n",
        "print(f\"Train columns: {list(train_df.columns)}\")\n",
        "print(f\"Features columns: {list(features_df.columns)}\")\n",
        "print(f\"Date range: {train_df['Date'].min()} to {train_df['Date'].max()}\")\n",
        "\n",
        "# Log basic info\n",
        "wandb.log({\n",
        "    \"train_samples\": len(train_df),\n",
        "    \"test_samples\": len(test_df),\n",
        "    \"n_stores\": train_df['Store'].nunique(),\n",
        "    \"n_departments\": train_df['Dept'].nunique(),\n",
        "    \"date_range_days\": (train_df['Date'].max() - train_df['Date'].min()).days\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yonCcvehBudv",
        "outputId": "312cb768-0cc0-4958-8106-6069b2afd191"
      },
      "id": "yonCcvehBudv",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Data loaded: Train (421570, 5), Test (115064, 4)\n",
            "Train columns: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday']\n",
            "Features columns: ['Store', 'Date', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday']\n",
            "Date range: 2010-02-05 00:00:00 to 2012-10-26 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Comprehensive logging suppression\n",
        "logging.getLogger('prophet').setLevel(logging.CRITICAL)\n",
        "logging.getLogger('cmdstanpy').setLevel(logging.CRITICAL)\n",
        "logging.getLogger('stan').setLevel(logging.CRITICAL)\n",
        "logging.getLogger('pystan').setLevel(logging.CRITICAL)\n",
        "\n",
        "# Set root logger to suppress everything below ERROR\n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "# Suppress specific loggers that might still show up\n",
        "for logger_name in ['prophet', 'cmdstanpy', 'stan', 'pystan', 'fbprophet']:\n",
        "    logging.getLogger(logger_name).setLevel(logging.CRITICAL)\n",
        "    logging.getLogger(logger_name).disabled = True\n",
        "\n",
        "# Also suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "\n",
        "# Suppress stdout/stderr for Stan compilation\n",
        "os.environ['CMDSTAN_VERBOSE'] = '0'"
      ],
      "metadata": {
        "id": "X-t2NxUtDxiN"
      },
      "id": "X-t2NxUtDxiN",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Block 2: Time Series Feature Engineering\n",
        "# =============================================================================\n",
        "\n",
        "class TimeSeriesFeatureEngineer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Focused time series feature engineering for Prophet\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.fitted = False\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.fitted = True\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        df = X.copy()\n",
        "        print(f\"Input shape: {df.shape}\")\n",
        "        print(f\"Input columns: {list(df.columns)}\")\n",
        "\n",
        "        # Merge external features with proper suffix handling\n",
        "        print(\"Merging with features...\")\n",
        "        df = df.merge(features_df, on=['Store', 'Date'], how='left', suffixes=('', '_feat'))\n",
        "        print(f\"After features merge: {df.shape}\")\n",
        "\n",
        "        print(\"Merging with stores...\")\n",
        "        df = df.merge(stores_df, on='Store', how='left')\n",
        "        print(f\"After stores merge: {df.shape}\")\n",
        "        print(f\"Columns after merge: {list(df.columns)}\")\n",
        "\n",
        "        # Handle IsHoliday column conflicts\n",
        "        if 'IsHoliday_feat' in df.columns:\n",
        "            # Use the original IsHoliday, fill missing with features version\n",
        "            df['IsHoliday'] = df['IsHoliday'].fillna(df['IsHoliday_feat'])\n",
        "            df = df.drop('IsHoliday_feat', axis=1)\n",
        "\n",
        "        # Ensure IsHoliday exists and is properly formatted\n",
        "        if 'IsHoliday' in df.columns:\n",
        "            df['IsHoliday'] = df['IsHoliday'].fillna(False).astype(int)\n",
        "        else:\n",
        "            print(\"Warning: IsHoliday column not found, creating default\")\n",
        "            df['IsHoliday'] = 0\n",
        "\n",
        "        # Fill missing values efficiently\n",
        "        numeric_cols = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
        "        for col in numeric_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].fillna(df[col].median())\n",
        "                print(f\"Filled {col}: {df[col].isnull().sum()} missing values\")\n",
        "            else:\n",
        "                print(f\"Warning: {col} not found in data\")\n",
        "\n",
        "        # Markdown columns (promotional effects)\n",
        "        markdown_cols = [f'MarkDown{i}' for i in range(1, 6)]\n",
        "        for col in markdown_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].fillna(0)\n",
        "            else:\n",
        "                print(f\"Creating {col} with default values\")\n",
        "                df[col] = 0\n",
        "\n",
        "        # Store type encoding\n",
        "        if 'Type' in df.columns:\n",
        "            df['Type'] = df['Type'].fillna('A')\n",
        "            print(f\"Store types: {df['Type'].value_counts()}\")\n",
        "        else:\n",
        "            print(\"Warning: Type column not found\")\n",
        "            df['Type'] = 'A'\n",
        "\n",
        "        if 'Size' in df.columns:\n",
        "            df['Size'] = df['Size'].fillna(df['Size'].median())\n",
        "        else:\n",
        "            print(\"Warning: Size column not found\")\n",
        "            df['Size'] = 151315  # Approximate median from typical Walmart data\n",
        "\n",
        "        # Time-based features for Prophet regressors\n",
        "        df['Month'] = df['Date'].dt.month\n",
        "        df['Quarter'] = df['Date'].dt.quarter\n",
        "        df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
        "        df['Week'] = df['Date'].dt.isocalendar().week\n",
        "\n",
        "        # Seasonal indicators (key for retail)\n",
        "        df['IsQ4'] = (df['Quarter'] == 4).astype(int)  # Holiday season\n",
        "        df['IsBackToSchool'] = (df['Month'] == 8).astype(int)  # August\n",
        "        df['IsSpringCleaning'] = (df['Month'] == 4).astype(int)  # April\n",
        "        df['IsSummer'] = df['Month'].isin([6, 7, 8]).astype(int)  # Summer\n",
        "\n",
        "        # Create total markdown effect\n",
        "        df['TotalMarkDown'] = sum(df[col] for col in markdown_cols if col in df.columns)\n",
        "\n",
        "        # Economic indicators\n",
        "        if 'CPI' in df.columns and 'Unemployment' in df.columns:\n",
        "            df['EconomicIndex'] = df['CPI'] * df['Unemployment']\n",
        "        else:\n",
        "            df['EconomicIndex'] = 0\n",
        "\n",
        "        # Store size category\n",
        "        if 'Size' in df.columns:\n",
        "            df['StoreSizeCategory'] = pd.cut(df['Size'], bins=3, labels=[0, 1, 2]).astype(int)\n",
        "        else:\n",
        "            df['StoreSizeCategory'] = 1\n",
        "\n",
        "        print(f\"Final processed shape: {df.shape}\")\n",
        "        print(f\"Missing values check:\")\n",
        "        for col in ['IsHoliday', 'Temperature', 'Fuel_Price', 'TotalMarkDown']:\n",
        "            if col in df.columns:\n",
        "                print(f\"  {col}: {df[col].isnull().sum()} missing\")\n",
        "\n",
        "        return df"
      ],
      "metadata": {
        "id": "Xm2LNySnrp4G"
      },
      "id": "Xm2LNySnrp4G",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Block 3: Prophet Model for Time Series\n",
        "# =============================================================================\n",
        "\n",
        "class SuppressOutput:\n",
        "    \"\"\"Enhanced context manager to suppress all output\"\"\"\n",
        "    def __enter__(self):\n",
        "        self._original_stdout = sys.stdout\n",
        "        self._original_stderr = sys.stderr\n",
        "        sys.stdout = open(os.devnull, 'w')\n",
        "        sys.stderr = open(os.devnull, 'w')\n",
        "\n",
        "        # Also suppress logging within context\n",
        "        self._original_level = logging.getLogger().level\n",
        "        logging.getLogger().setLevel(logging.CRITICAL)\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout.close()\n",
        "        sys.stderr.close()\n",
        "        sys.stdout = self._original_stdout\n",
        "        sys.stderr = self._original_stderr\n",
        "        logging.getLogger().setLevel(self._original_level)\n",
        "\n",
        "class WalmartProphetModel(BaseEstimator):\n",
        "    \"\"\"Optimized Prophet model for Walmart sales forecasting\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 changepoint_prior_scale=0.05,\n",
        "                 seasonality_prior_scale=10.0,\n",
        "                 holidays_prior_scale=10.0,\n",
        "                 seasonality_mode='multiplicative',\n",
        "                 min_samples=20):\n",
        "        self.changepoint_prior_scale = changepoint_prior_scale\n",
        "        self.seasonality_prior_scale = seasonality_prior_scale\n",
        "        self.holidays_prior_scale = holidays_prior_scale\n",
        "        self.seasonality_mode = seasonality_mode\n",
        "        self.min_samples = min_samples\n",
        "        self.models = {}\n",
        "        self.global_median = None\n",
        "\n",
        "    def _create_holidays(self, df):\n",
        "        \"\"\"Create holiday dataframe for Prophet\"\"\"\n",
        "        # Create base holidays\n",
        "        base_holidays = {\n",
        "            'thanksgiving': ['2010-11-25', '2011-11-24', '2012-11-22', '2013-11-28'],\n",
        "            'christmas': ['2010-12-25', '2011-12-25', '2012-12-25', '2013-12-25'],\n",
        "            'newyear': ['2011-01-01', '2012-01-01', '2013-01-01', '2014-01-01'],\n",
        "            'superbowl': ['2011-02-06', '2012-02-05', '2013-02-03', '2014-02-02'],\n",
        "            'laborday': ['2010-09-06', '2011-09-05', '2012-09-03', '2013-09-02']\n",
        "        }\n",
        "\n",
        "        holidays_list = []\n",
        "        for holiday_name, dates in base_holidays.items():\n",
        "            for date_str in dates:\n",
        "                holidays_list.append({\n",
        "                    'holiday': holiday_name,\n",
        "                    'ds': pd.to_datetime(date_str),\n",
        "                    'lower_window': 0,\n",
        "                    'upper_window': 0\n",
        "                })\n",
        "\n",
        "        return pd.DataFrame(holidays_list)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"Fit Prophet models for each store-department combination\"\"\"\n",
        "        print(f\"Training Prophet models...\")\n",
        "\n",
        "        # Calculate global median for fallback\n",
        "        if 'Weekly_Sales' in X.columns:\n",
        "            self.global_median = X['Weekly_Sales'].median()\n",
        "        else:\n",
        "            self.global_median = 15000  # Reasonable default\n",
        "\n",
        "        # Create holidays\n",
        "        holidays = self._create_holidays(X)\n",
        "\n",
        "        # Key regressors for Prophet (only use columns that exist)\n",
        "        potential_regressors = [\n",
        "            'Temperature', 'Fuel_Price', 'IsHoliday', 'IsQ4',\n",
        "            'IsBackToSchool', 'TotalMarkDown', 'EconomicIndex', 'IsSummer'\n",
        "        ]\n",
        "\n",
        "        # Filter to only existing columns\n",
        "        regressors = [col for col in potential_regressors if col in X.columns]\n",
        "        print(f\"Using regressors: {regressors}\")\n",
        "\n",
        "        trained_count = 0\n",
        "        total_groups = len(X.groupby(['Store', 'Dept']))\n",
        "\n",
        "        for i, ((store, dept), group) in enumerate(X.groupby(['Store', 'Dept'])):\n",
        "            if i % 50 == 0:\n",
        "                print(f\"Progress: {i}/{total_groups} ({100*i/total_groups:.1f}%)\")\n",
        "\n",
        "            # Skip if insufficient data\n",
        "            if len(group) < self.min_samples:\n",
        "                continue\n",
        "\n",
        "            # Prepare data for Prophet\n",
        "            prophet_data = pd.DataFrame({\n",
        "                'ds': group['Date'],\n",
        "                'y': group['Weekly_Sales'] if 'Weekly_Sales' in group.columns else group.iloc[:, -1]  # fallback\n",
        "            })\n",
        "\n",
        "            # Add regressors\n",
        "            for regressor in regressors:\n",
        "                if regressor in group.columns:\n",
        "                    prophet_data[regressor] = group[regressor].values\n",
        "                else:\n",
        "                    prophet_data[regressor] = 0  # Default value\n",
        "\n",
        "            # Remove any remaining NaN values\n",
        "            prophet_data = prophet_data.dropna()\n",
        "\n",
        "            if len(prophet_data) < self.min_samples:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                with SuppressOutput():\n",
        "                    # Initialize Prophet model\n",
        "                    model = Prophet(\n",
        "                        changepoint_prior_scale=self.changepoint_prior_scale,\n",
        "                        seasonality_prior_scale=self.seasonality_prior_scale,\n",
        "                        holidays_prior_scale=self.holidays_prior_scale,\n",
        "                        seasonality_mode=self.seasonality_mode,\n",
        "                        holidays=holidays,\n",
        "                        daily_seasonality=False,\n",
        "                        weekly_seasonality=True,\n",
        "                        yearly_seasonality=True\n",
        "                    )\n",
        "\n",
        "                    # Add regressors\n",
        "                    for regressor in regressors:\n",
        "                        if regressor in prophet_data.columns:\n",
        "                            model.add_regressor(regressor)\n",
        "\n",
        "                    # Fit model\n",
        "                    model.fit(prophet_data)\n",
        "\n",
        "                    # Store model and info\n",
        "                    self.models[(store, dept)] = {\n",
        "                        'model': model,\n",
        "                        'regressors': regressors,\n",
        "                        'median_sales': prophet_data['y'].median()\n",
        "                    }\n",
        "                    trained_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                # Skip problematic series\n",
        "                if i < 5:  # Show first few errors for debugging\n",
        "                    print(f\"Error training model for Store {store}, Dept {dept}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"Successfully trained {trained_count} models out of {total_groups} store-dept combinations\")\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Generate predictions using trained Prophet models\"\"\"\n",
        "        predictions = []\n",
        "\n",
        "        for (store, dept), group in X.groupby(['Store', 'Dept']):\n",
        "            if (store, dept) in self.models:\n",
        "                model_info = self.models[(store, dept)]\n",
        "                model = model_info['model']\n",
        "\n",
        "                # Prepare future dataframe\n",
        "                future = pd.DataFrame({'ds': group['Date']})\n",
        "\n",
        "                # Add regressors\n",
        "                for regressor in model_info['regressors']:\n",
        "                    if regressor in group.columns:\n",
        "                        future[regressor] = group[regressor].values\n",
        "                    else:\n",
        "                        future[regressor] = 0\n",
        "\n",
        "                try:\n",
        "                    with SuppressOutput():\n",
        "                        forecast = model.predict(future)\n",
        "                    predictions.extend(forecast['yhat'].values)\n",
        "                except Exception as e:\n",
        "                    # Fallback to median\n",
        "                    median_pred = model_info['median_sales']\n",
        "                    predictions.extend([median_pred] * len(group))\n",
        "            else:\n",
        "                # Use global median for unseen store-dept combinations\n",
        "                # Apply seasonal adjustment\n",
        "                seasonal_multiplier = 1.0\n",
        "                if 'Month' in group.columns:\n",
        "                    month = group['Month'].iloc[0]\n",
        "                    if month in [11, 12]:  # Holiday season\n",
        "                        seasonal_multiplier = 1.5\n",
        "                    elif month in [1, 2]:  # Post holiday\n",
        "                        seasonal_multiplier = 0.8\n",
        "\n",
        "                pred_value = self.global_median * seasonal_multiplier\n",
        "                predictions.extend([pred_value] * len(group))\n",
        "\n",
        "        return np.array(predictions)"
      ],
      "metadata": {
        "id": "sVybN6D3rs1Y"
      },
      "id": "sVybN6D3rs1Y",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Block 4: Pipeline Training and Evaluation\n",
        "# =============================================================================\n",
        "\n",
        "# Feature engineering\n",
        "print(\"Applying feature engineering...\")\n",
        "feature_engineer = TimeSeriesFeatureEngineer()\n",
        "feature_engineer.fit(train_df)\n",
        "\n",
        "processed_train = feature_engineer.transform(train_df)\n",
        "processed_test = feature_engineer.transform(test_df)\n",
        "\n",
        "print(f\"Features added. Train shape: {processed_train.shape}\")\n",
        "\n",
        "# Time-based train/validation split\n",
        "print(\"Creating time-based validation split...\")\n",
        "max_date = processed_train['Date'].max()\n",
        "val_split_date = max_date - timedelta(weeks=8)\n",
        "\n",
        "train_data = processed_train[processed_train['Date'] <= val_split_date].copy()\n",
        "val_data = processed_train[processed_train['Date'] > val_split_date].copy()\n",
        "\n",
        "print(f\"Train: {len(train_data)} samples, Val: {len(val_data)} samples\")\n",
        "\n",
        "# Train Prophet model\n",
        "print(\"Training Prophet model...\")\n",
        "prophet_model = WalmartProphetModel(\n",
        "    changepoint_prior_scale=0.08,      # Small increase from 0.05\n",
        "    seasonality_prior_scale=12.0,      # Small increase from 10.0\n",
        "    holidays_prior_scale=15.0,         # Modest increase from 10.0 (holidays matter most in retail)\n",
        "    seasonality_mode='multiplicative',  # Keep same\n",
        "    min_samples=18                      # Slightly reduced from 20\n",
        ")\n",
        "\n",
        "prophet_model.fit(train_data)\n",
        "\n",
        "# Validate\n",
        "print(\"Validating model...\")\n",
        "val_predictions = prophet_model.predict(val_data)\n",
        "val_mae = mean_absolute_error(val_data['Weekly_Sales'], val_predictions)\n",
        "print(f\"Validation MAE: {val_mae:.2f}\")\n",
        "\n",
        "# Log validation results\n",
        "wandb.log({\n",
        "    'validation_mae': val_mae,\n",
        "    'models_trained': len(prophet_model.models),\n",
        "    'val_samples': len(val_data)\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1shxcctsrvNL",
        "outputId": "813acc32-0a4d-4293-f218-117d02b0d10c"
      },
      "id": "1shxcctsrvNL",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying feature engineering...\n",
            "Input shape: (421570, 5)\n",
            "Input columns: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday']\n",
            "Merging with features...\n",
            "After features merge: (421570, 15)\n",
            "Merging with stores...\n",
            "After stores merge: (421570, 17)\n",
            "Columns after merge: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday_feat', 'Type', 'Size']\n",
            "Filled Temperature: 0 missing values\n",
            "Filled Fuel_Price: 0 missing values\n",
            "Filled CPI: 0 missing values\n",
            "Filled Unemployment: 0 missing values\n",
            "Store types: Type\n",
            "A    215478\n",
            "B    163495\n",
            "C     42597\n",
            "Name: count, dtype: int64\n",
            "Final processed shape: (421570, 27)\n",
            "Missing values check:\n",
            "  IsHoliday: 0 missing\n",
            "  Temperature: 0 missing\n",
            "  Fuel_Price: 0 missing\n",
            "  TotalMarkDown: 0 missing\n",
            "Input shape: (115064, 4)\n",
            "Input columns: ['Store', 'Dept', 'Date', 'IsHoliday']\n",
            "Merging with features...\n",
            "After features merge: (115064, 14)\n",
            "Merging with stores...\n",
            "After stores merge: (115064, 16)\n",
            "Columns after merge: ['Store', 'Dept', 'Date', 'IsHoliday', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday_feat', 'Type', 'Size']\n",
            "Filled Temperature: 0 missing values\n",
            "Filled Fuel_Price: 0 missing values\n",
            "Filled CPI: 0 missing values\n",
            "Filled Unemployment: 0 missing values\n",
            "Store types: Type\n",
            "A    58713\n",
            "B    44500\n",
            "C    11851\n",
            "Name: count, dtype: int64\n",
            "Final processed shape: (115064, 26)\n",
            "Missing values check:\n",
            "  IsHoliday: 0 missing\n",
            "  Temperature: 0 missing\n",
            "  Fuel_Price: 0 missing\n",
            "  TotalMarkDown: 0 missing\n",
            "Features added. Train shape: (421570, 27)\n",
            "Creating time-based validation split...\n",
            "Train: 397841 samples, Val: 23729 samples\n",
            "Training Prophet model...\n",
            "Training Prophet models...\n",
            "Using regressors: ['Temperature', 'Fuel_Price', 'IsHoliday', 'IsQ4', 'IsBackToSchool', 'TotalMarkDown', 'EconomicIndex', 'IsSummer']\n",
            "Progress: 0/3326 (0.0%)\n",
            "Progress: 50/3326 (1.5%)\n",
            "Progress: 100/3326 (3.0%)\n",
            "Progress: 150/3326 (4.5%)\n",
            "Progress: 200/3326 (6.0%)\n",
            "Progress: 250/3326 (7.5%)\n",
            "Progress: 300/3326 (9.0%)\n",
            "Progress: 350/3326 (10.5%)\n",
            "Progress: 400/3326 (12.0%)\n",
            "Progress: 450/3326 (13.5%)\n",
            "Progress: 500/3326 (15.0%)\n",
            "Progress: 550/3326 (16.5%)\n",
            "Progress: 600/3326 (18.0%)\n",
            "Progress: 650/3326 (19.5%)\n",
            "Progress: 700/3326 (21.0%)\n",
            "Progress: 750/3326 (22.5%)\n",
            "Progress: 800/3326 (24.1%)\n",
            "Progress: 850/3326 (25.6%)\n",
            "Progress: 900/3326 (27.1%)\n",
            "Progress: 950/3326 (28.6%)\n",
            "Progress: 1000/3326 (30.1%)\n",
            "Progress: 1050/3326 (31.6%)\n",
            "Progress: 1100/3326 (33.1%)\n",
            "Progress: 1150/3326 (34.6%)\n",
            "Progress: 1200/3326 (36.1%)\n",
            "Progress: 1250/3326 (37.6%)\n",
            "Progress: 1300/3326 (39.1%)\n",
            "Progress: 1350/3326 (40.6%)\n",
            "Progress: 1400/3326 (42.1%)\n",
            "Progress: 1450/3326 (43.6%)\n",
            "Progress: 1500/3326 (45.1%)\n",
            "Progress: 1550/3326 (46.6%)\n",
            "Progress: 1600/3326 (48.1%)\n",
            "Progress: 1650/3326 (49.6%)\n",
            "Progress: 1700/3326 (51.1%)\n",
            "Progress: 1750/3326 (52.6%)\n",
            "Progress: 1800/3326 (54.1%)\n",
            "Progress: 1850/3326 (55.6%)\n",
            "Progress: 1900/3326 (57.1%)\n",
            "Progress: 1950/3326 (58.6%)\n",
            "Progress: 2000/3326 (60.1%)\n",
            "Progress: 2050/3326 (61.6%)\n",
            "Progress: 2100/3326 (63.1%)\n",
            "Progress: 2150/3326 (64.6%)\n",
            "Progress: 2200/3326 (66.1%)\n",
            "Progress: 2250/3326 (67.6%)\n",
            "Progress: 2300/3326 (69.2%)\n",
            "Progress: 2350/3326 (70.7%)\n",
            "Progress: 2400/3326 (72.2%)\n",
            "Progress: 2450/3326 (73.7%)\n",
            "Progress: 2500/3326 (75.2%)\n",
            "Progress: 2550/3326 (76.7%)\n",
            "Progress: 2600/3326 (78.2%)\n",
            "Progress: 2650/3326 (79.7%)\n",
            "Progress: 2700/3326 (81.2%)\n",
            "Progress: 2750/3326 (82.7%)\n",
            "Progress: 2800/3326 (84.2%)\n",
            "Progress: 2850/3326 (85.7%)\n",
            "Progress: 2900/3326 (87.2%)\n",
            "Progress: 2950/3326 (88.7%)\n",
            "Progress: 3000/3326 (90.2%)\n",
            "Progress: 3050/3326 (91.7%)\n",
            "Progress: 3100/3326 (93.2%)\n",
            "Progress: 3150/3326 (94.7%)\n",
            "Progress: 3200/3326 (96.2%)\n",
            "Progress: 3250/3326 (97.7%)\n",
            "Progress: 3300/3326 (99.2%)\n",
            "Successfully trained 3093 models out of 3326 store-dept combinations\n",
            "Validating model...\n",
            "Validation MAE: 1897.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Block 5: Final Training and Prediction\n",
        "# =============================================================================\n",
        "\n",
        "print(\"Training final model on full dataset...\")\n",
        "final_model = WalmartProphetModel(\n",
        "    changepoint_prior_scale=0.05,\n",
        "    seasonality_prior_scale=10.0,\n",
        "    seasonality_mode='multiplicative'\n",
        ")\n",
        "\n",
        "final_model.fit(processed_train)\n",
        "\n",
        "# Generate test predictions\n",
        "print(\"Generating test predictions...\")\n",
        "test_predictions = final_model.predict(processed_test)\n",
        "\n",
        "# Basic sanity check\n",
        "print(f\"Test predictions stats:\")\n",
        "print(f\"  Mean: {np.mean(test_predictions):.2f}\")\n",
        "print(f\"  Std: {np.std(test_predictions):.2f}\")\n",
        "print(f\"  Min: {np.min(test_predictions):.2f}\")\n",
        "print(f\"  Max: {np.max(test_predictions):.2f}\")\n",
        "\n",
        "# Create submission\n",
        "submission = sample_submission.copy()\n",
        "submission['Weekly_Sales'] = test_predictions\n",
        "\n",
        "# Save results\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "submission_filename = f'prophet_submission_{timestamp}.csv'\n",
        "submission.to_csv(submission_filename, index=False)\n",
        "\n",
        "print(f\"Submission saved: {submission_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p79z3HFMrhAG",
        "outputId": "666be4ae-695f-4637-bab6-9964aa3bd37d"
      },
      "id": "p79z3HFMrhAG",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training final model on full dataset...\n",
            "Training Prophet models...\n",
            "Using regressors: ['Temperature', 'Fuel_Price', 'IsHoliday', 'IsQ4', 'IsBackToSchool', 'TotalMarkDown', 'EconomicIndex', 'IsSummer']\n",
            "Progress: 0/3331 (0.0%)\n",
            "Progress: 50/3331 (1.5%)\n",
            "Progress: 100/3331 (3.0%)\n",
            "Progress: 150/3331 (4.5%)\n",
            "Progress: 200/3331 (6.0%)\n",
            "Progress: 250/3331 (7.5%)\n",
            "Progress: 300/3331 (9.0%)\n",
            "Progress: 350/3331 (10.5%)\n",
            "Progress: 400/3331 (12.0%)\n",
            "Progress: 450/3331 (13.5%)\n",
            "Progress: 500/3331 (15.0%)\n",
            "Progress: 550/3331 (16.5%)\n",
            "Progress: 600/3331 (18.0%)\n",
            "Progress: 650/3331 (19.5%)\n",
            "Progress: 700/3331 (21.0%)\n",
            "Progress: 750/3331 (22.5%)\n",
            "Progress: 800/3331 (24.0%)\n",
            "Progress: 850/3331 (25.5%)\n",
            "Progress: 900/3331 (27.0%)\n",
            "Progress: 950/3331 (28.5%)\n",
            "Progress: 1000/3331 (30.0%)\n",
            "Progress: 1050/3331 (31.5%)\n",
            "Progress: 1100/3331 (33.0%)\n",
            "Progress: 1150/3331 (34.5%)\n",
            "Progress: 1200/3331 (36.0%)\n",
            "Progress: 1250/3331 (37.5%)\n",
            "Progress: 1300/3331 (39.0%)\n",
            "Progress: 1350/3331 (40.5%)\n",
            "Progress: 1400/3331 (42.0%)\n",
            "Progress: 1450/3331 (43.5%)\n",
            "Progress: 1500/3331 (45.0%)\n",
            "Progress: 1550/3331 (46.5%)\n",
            "Progress: 1600/3331 (48.0%)\n",
            "Progress: 1650/3331 (49.5%)\n",
            "Progress: 1700/3331 (51.0%)\n",
            "Progress: 1750/3331 (52.5%)\n",
            "Progress: 1800/3331 (54.0%)\n",
            "Progress: 1850/3331 (55.5%)\n",
            "Progress: 1900/3331 (57.0%)\n",
            "Progress: 1950/3331 (58.5%)\n",
            "Progress: 2000/3331 (60.0%)\n",
            "Progress: 2050/3331 (61.5%)\n",
            "Progress: 2100/3331 (63.0%)\n",
            "Progress: 2150/3331 (64.5%)\n",
            "Progress: 2200/3331 (66.0%)\n",
            "Progress: 2250/3331 (67.5%)\n",
            "Progress: 2300/3331 (69.0%)\n",
            "Progress: 2350/3331 (70.5%)\n",
            "Progress: 2400/3331 (72.1%)\n",
            "Progress: 2450/3331 (73.6%)\n",
            "Progress: 2500/3331 (75.1%)\n",
            "Progress: 2550/3331 (76.6%)\n",
            "Progress: 2600/3331 (78.1%)\n",
            "Progress: 2650/3331 (79.6%)\n",
            "Progress: 2700/3331 (81.1%)\n",
            "Progress: 2750/3331 (82.6%)\n",
            "Progress: 2800/3331 (84.1%)\n",
            "Progress: 2850/3331 (85.6%)\n",
            "Progress: 2900/3331 (87.1%)\n",
            "Progress: 2950/3331 (88.6%)\n",
            "Progress: 3000/3331 (90.1%)\n",
            "Progress: 3050/3331 (91.6%)\n",
            "Progress: 3100/3331 (93.1%)\n",
            "Progress: 3150/3331 (94.6%)\n",
            "Progress: 3200/3331 (96.1%)\n",
            "Progress: 3250/3331 (97.6%)\n",
            "Progress: 3300/3331 (99.1%)\n",
            "Successfully trained 3087 models out of 3331 store-dept combinations\n",
            "Generating test predictions...\n",
            "Test predictions stats:\n",
            "  Mean: 15946.43\n",
            "  Std: 22678.70\n",
            "  Min: -77274.62\n",
            "  Max: 361954.49\n",
            "Submission saved: prophet_submission_20250731_203500.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Block 6: Pipeline Saving and Artifact Creation\n",
        "# =============================================================================\n",
        "\n",
        "class WalmartProphetPipeline(BaseEstimator):\n",
        "    \"\"\"Complete pipeline for Walmart sales forecasting\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.feature_engineer = TimeSeriesFeatureEngineer()\n",
        "        self.model = WalmartProphetModel()\n",
        "        self.fitted = False\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        print(\"Fitting complete pipeline...\")\n",
        "        processed_data = self.feature_engineer.fit_transform(X)\n",
        "        self.model.fit(processed_data)\n",
        "        self.fitted = True\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not self.fitted:\n",
        "            raise ValueError(\"Pipeline must be fitted before prediction\")\n",
        "        processed_data = self.feature_engineer.transform(X)\n",
        "        return self.model.predict(processed_data)\n",
        "\n",
        "# Create and save pipeline\n",
        "print(\"Creating complete pipeline...\")\n",
        "pipeline = WalmartProphetPipeline()\n",
        "pipeline.fit(train_df)\n",
        "\n",
        "# Save pipeline\n",
        "pipeline_filename = f'walmart_prophet_pipeline_{timestamp}.pkl'\n",
        "with open(pipeline_filename, 'wb') as f:\n",
        "    dill.dump(pipeline, f)\n",
        "\n",
        "print(f\"Pipeline saved: {pipeline_filename}\")\n",
        "\n",
        "# Create WandB artifacts\n",
        "pipeline_artifact = wandb.Artifact(\n",
        "    name=\"walmart_prophet_pipeline\",\n",
        "    type=\"model\",\n",
        "    description=\"Complete Prophet pipeline for Walmart sales forecasting\",\n",
        "    metadata={\n",
        "        \"model_type\": \"Prophet\",\n",
        "        \"validation_mae\": val_mae,\n",
        "        \"models_trained\": len(final_model.models),\n",
        "        \"timestamp\": timestamp\n",
        "    }\n",
        ")\n",
        "\n",
        "pipeline_artifact.add_file(pipeline_filename)\n",
        "wandb.log_artifact(pipeline_artifact)\n",
        "\n",
        "submission_artifact = wandb.Artifact(\n",
        "    name=\"walmart_prophet_submission\",\n",
        "    type=\"dataset\",\n",
        "    description=f\"Prophet submission for Walmart sales - {timestamp}\"\n",
        ")\n",
        "submission_artifact.add_file(submission_filename)\n",
        "wandb.log_artifact(submission_artifact)\n",
        "\n",
        "# Final logging\n",
        "wandb.log({\n",
        "    'pipeline_saved': True,\n",
        "    'submission_created': True,\n",
        "    'test_predictions_mean': np.mean(test_predictions),\n",
        "    'test_predictions_std': np.std(test_predictions),\n",
        "    'final_models_count': len(final_model.models)\n",
        "})\n",
        "\n",
        "print(\"Walmart Prophet forecasting completed successfully!\")\n",
        "print(f\"Validation MAE: {val_mae:.2f}\")\n",
        "print(f\"Models trained: {len(final_model.models)}\")\n",
        "print(\"Pipeline and submission saved to WandB!\")\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5WWvqh8drzoY",
        "outputId": "af523fd9-8a5d-4e6e-a7f7-38a95e38ed08"
      },
      "id": "5WWvqh8drzoY",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating complete pipeline...\n",
            "Fitting complete pipeline...\n",
            "Input shape: (421570, 5)\n",
            "Input columns: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday']\n",
            "Merging with features...\n",
            "After features merge: (421570, 15)\n",
            "Merging with stores...\n",
            "After stores merge: (421570, 17)\n",
            "Columns after merge: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday_feat', 'Type', 'Size']\n",
            "Filled Temperature: 0 missing values\n",
            "Filled Fuel_Price: 0 missing values\n",
            "Filled CPI: 0 missing values\n",
            "Filled Unemployment: 0 missing values\n",
            "Store types: Type\n",
            "A    215478\n",
            "B    163495\n",
            "C     42597\n",
            "Name: count, dtype: int64\n",
            "Final processed shape: (421570, 27)\n",
            "Missing values check:\n",
            "  IsHoliday: 0 missing\n",
            "  Temperature: 0 missing\n",
            "  Fuel_Price: 0 missing\n",
            "  TotalMarkDown: 0 missing\n",
            "Training Prophet models...\n",
            "Using regressors: ['Temperature', 'Fuel_Price', 'IsHoliday', 'IsQ4', 'IsBackToSchool', 'TotalMarkDown', 'EconomicIndex', 'IsSummer']\n",
            "Progress: 0/3331 (0.0%)\n",
            "Progress: 50/3331 (1.5%)\n",
            "Progress: 100/3331 (3.0%)\n",
            "Progress: 150/3331 (4.5%)\n",
            "Progress: 200/3331 (6.0%)\n",
            "Progress: 250/3331 (7.5%)\n",
            "Progress: 300/3331 (9.0%)\n",
            "Progress: 350/3331 (10.5%)\n",
            "Progress: 400/3331 (12.0%)\n",
            "Progress: 450/3331 (13.5%)\n",
            "Progress: 500/3331 (15.0%)\n",
            "Progress: 550/3331 (16.5%)\n",
            "Progress: 600/3331 (18.0%)\n",
            "Progress: 650/3331 (19.5%)\n",
            "Progress: 700/3331 (21.0%)\n",
            "Progress: 750/3331 (22.5%)\n",
            "Progress: 800/3331 (24.0%)\n",
            "Progress: 850/3331 (25.5%)\n",
            "Progress: 900/3331 (27.0%)\n",
            "Progress: 950/3331 (28.5%)\n",
            "Progress: 1000/3331 (30.0%)\n",
            "Progress: 1050/3331 (31.5%)\n",
            "Progress: 1100/3331 (33.0%)\n",
            "Progress: 1150/3331 (34.5%)\n",
            "Progress: 1200/3331 (36.0%)\n",
            "Progress: 1250/3331 (37.5%)\n",
            "Progress: 1300/3331 (39.0%)\n",
            "Progress: 1350/3331 (40.5%)\n",
            "Progress: 1400/3331 (42.0%)\n",
            "Progress: 1450/3331 (43.5%)\n",
            "Progress: 1500/3331 (45.0%)\n",
            "Progress: 1550/3331 (46.5%)\n",
            "Progress: 1600/3331 (48.0%)\n",
            "Progress: 1650/3331 (49.5%)\n",
            "Progress: 1700/3331 (51.0%)\n",
            "Progress: 1750/3331 (52.5%)\n",
            "Progress: 1800/3331 (54.0%)\n",
            "Progress: 1850/3331 (55.5%)\n",
            "Progress: 1900/3331 (57.0%)\n",
            "Progress: 1950/3331 (58.5%)\n",
            "Progress: 2000/3331 (60.0%)\n",
            "Progress: 2050/3331 (61.5%)\n",
            "Progress: 2100/3331 (63.0%)\n",
            "Progress: 2150/3331 (64.5%)\n",
            "Progress: 2200/3331 (66.0%)\n",
            "Progress: 2250/3331 (67.5%)\n",
            "Progress: 2300/3331 (69.0%)\n",
            "Progress: 2350/3331 (70.5%)\n",
            "Progress: 2400/3331 (72.1%)\n",
            "Progress: 2450/3331 (73.6%)\n",
            "Progress: 2500/3331 (75.1%)\n",
            "Progress: 2550/3331 (76.6%)\n",
            "Progress: 2600/3331 (78.1%)\n",
            "Progress: 2650/3331 (79.6%)\n",
            "Progress: 2700/3331 (81.1%)\n",
            "Progress: 2750/3331 (82.6%)\n",
            "Progress: 2800/3331 (84.1%)\n",
            "Progress: 2850/3331 (85.6%)\n",
            "Progress: 2900/3331 (87.1%)\n",
            "Progress: 2950/3331 (88.6%)\n",
            "Progress: 3000/3331 (90.1%)\n",
            "Progress: 3050/3331 (91.6%)\n",
            "Progress: 3100/3331 (93.1%)\n",
            "Progress: 3150/3331 (94.6%)\n",
            "Progress: 3200/3331 (96.1%)\n",
            "Progress: 3250/3331 (97.6%)\n",
            "Progress: 3300/3331 (99.1%)\n",
            "Successfully trained 3087 models out of 3331 store-dept combinations\n",
            "Pipeline saved: walmart_prophet_pipeline_20250731_203500.pkl\n",
            "Walmart Prophet forecasting completed successfully!\n",
            "Validation MAE: 1897.07\n",
            "Models trained: 3087\n",
            "Pipeline and submission saved to WandB!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>date_range_days</td><td>▁</td></tr><tr><td>final_models_count</td><td>▁</td></tr><tr><td>models_trained</td><td>▁</td></tr><tr><td>n_departments</td><td>▁</td></tr><tr><td>n_stores</td><td>▁</td></tr><tr><td>test_predictions_mean</td><td>▁</td></tr><tr><td>test_predictions_std</td><td>▁</td></tr><tr><td>test_samples</td><td>▁</td></tr><tr><td>train_samples</td><td>▁</td></tr><tr><td>val_samples</td><td>▁</td></tr><tr><td>validation_mae</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>date_range_days</td><td>994</td></tr><tr><td>final_models_count</td><td>3087</td></tr><tr><td>models_trained</td><td>3093</td></tr><tr><td>n_departments</td><td>81</td></tr><tr><td>n_stores</td><td>45</td></tr><tr><td>pipeline_saved</td><td>True</td></tr><tr><td>submission_created</td><td>True</td></tr><tr><td>test_predictions_mean</td><td>15946.43347</td></tr><tr><td>test_predictions_std</td><td>22678.69668</td></tr><tr><td>test_samples</td><td>115064</td></tr><tr><td>train_samples</td><td>421570</td></tr><tr><td>val_samples</td><td>23729</td></tr><tr><td>validation_mae</td><td>1897.06913</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Prophet_TimeSeries_Optimized</strong> at: <a href='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting/runs/wh7gqtn4' target=\"_blank\">https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting/runs/wh7gqtn4</a><br> View project at: <a href='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250731_200326-wh7gqtn4/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}