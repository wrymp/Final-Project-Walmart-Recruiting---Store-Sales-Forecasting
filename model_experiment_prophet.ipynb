{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle wandb onnx -Uq\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xc_xtTn6ECN",
        "outputId": "37d5a687-2b89-40d4-905b-128450c6728a"
      },
      "id": "0xc_xtTn6ECN",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/Kaggle_credentials/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "3Q92W4PQ6EaA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8343baf9-169e-4a6a-e521-9087e53848ac"
      },
      "id": "3Q92W4PQ6EaA",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! kaggle competitions download -c walmart-recruiting-store-sales-forecasting"
      ],
      "metadata": {
        "id": "MPwqMv2z6H6S"
      },
      "id": "MPwqMv2z6H6S",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! unzip /content/walmart-recruiting-store-sales-forecasting.zip\n",
        "# ! unzip /content/train.csv.zip\n",
        "# ! unzip /content/test.csv.zip\n",
        "# ! unzip /content/features.csv.zip\n",
        "# ! unzip /content/sampleSubmission.csv.zip"
      ],
      "metadata": {
        "id": "jQr6E5zG6KBU"
      },
      "id": "jQr6E5zG6KBU",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install wandb -qU\n",
        "# !pip uninstall -y pmdarima numpy scipy statsmodels\n",
        "# !pip install numpy==1.24.4 scipy==1.10.1 statsmodels==0.13.5 pmdarima==2.0.3"
      ],
      "metadata": {
        "id": "myvAj7pC7CyH"
      },
      "id": "myvAj7pC7CyH",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import random\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "c5Vm5Z5I7DRW"
      },
      "id": "c5Vm5Z5I7DRW",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wandb\n",
        "import dill\n",
        "import logging\n",
        "from datetime import datetime, timedelta\n",
        "from prophet import Prophet\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings and logging\n",
        "warnings.filterwarnings('ignore')\n",
        "logging.getLogger('prophet').setLevel(logging.ERROR)\n",
        "logging.getLogger('cmdstanpy').setLevel(logging.ERROR)\n",
        "\n",
        "# WandB setup\n",
        "wandb.init(project=\"walmart-sales-forecasting\", name=\"Prophet_TimeSeries_Optimized\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "4B45831Qriot",
        "outputId": "210463a1-a050-4c7b-ccaf-0873904e60fd"
      },
      "id": "4B45831Qriot",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250730_234103-ckx8bwlx</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting/runs/ckx8bwlx' target=\"_blank\">Prophet_TimeSeries_Optimized</a></strong> to <a href='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting/runs/ckx8bwlx' target=\"_blank\">https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting/runs/ckx8bwlx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting/runs/ckx8bwlx?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7b089c0477d0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Block 1: Data Loading and Initial Setup\n",
        "# =============================================================================\n",
        "\n",
        "print(\"Loading data...\")\n",
        "train_df = pd.read_csv(\"/content/train.csv\")\n",
        "features_df = pd.read_csv(\"/content/features.csv\")\n",
        "stores_df = pd.read_csv(\"/content/stores.csv\")\n",
        "test_df = pd.read_csv(\"/content/test.csv\")\n",
        "sample_submission = pd.read_csv(\"/content/sampleSubmission.csv\")\n",
        "\n",
        "# Convert dates\n",
        "train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
        "test_df['Date'] = pd.to_datetime(test_df['Date'])\n",
        "features_df['Date'] = pd.to_datetime(features_df['Date'])\n",
        "\n",
        "print(f\"Data loaded: Train {train_df.shape}, Test {test_df.shape}\")\n",
        "print(f\"Train columns: {list(train_df.columns)}\")\n",
        "print(f\"Features columns: {list(features_df.columns)}\")\n",
        "print(f\"Date range: {train_df['Date'].min()} to {train_df['Date'].max()}\")\n",
        "\n",
        "# Log basic info\n",
        "wandb.log({\n",
        "    \"train_samples\": len(train_df),\n",
        "    \"test_samples\": len(test_df),\n",
        "    \"n_stores\": train_df['Store'].nunique(),\n",
        "    \"n_departments\": train_df['Dept'].nunique(),\n",
        "    \"date_range_days\": (train_df['Date'].max() - train_df['Date'].min()).days\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yonCcvehBudv",
        "outputId": "cdab49bd-10e9-44f2-bafb-bce7b5433d0b"
      },
      "id": "yonCcvehBudv",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Data loaded: Train (421570, 5), Test (115064, 4)\n",
            "Train columns: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday']\n",
            "Features columns: ['Store', 'Date', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday']\n",
            "Date range: 2010-02-05 00:00:00 to 2012-10-26 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Block 2: Time Series Feature Engineering\n",
        "# =============================================================================\n",
        "\n",
        "class TimeSeriesFeatureEngineer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Focused time series feature engineering for Prophet\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.fitted = False\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.fitted = True\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        df = X.copy()\n",
        "        print(f\"Input shape: {df.shape}\")\n",
        "        print(f\"Input columns: {list(df.columns)}\")\n",
        "\n",
        "        # Merge external features with proper suffix handling\n",
        "        print(\"Merging with features...\")\n",
        "        df = df.merge(features_df, on=['Store', 'Date'], how='left', suffixes=('', '_feat'))\n",
        "        print(f\"After features merge: {df.shape}\")\n",
        "\n",
        "        print(\"Merging with stores...\")\n",
        "        df = df.merge(stores_df, on='Store', how='left')\n",
        "        print(f\"After stores merge: {df.shape}\")\n",
        "        print(f\"Columns after merge: {list(df.columns)}\")\n",
        "\n",
        "        # Handle IsHoliday column conflicts\n",
        "        if 'IsHoliday_feat' in df.columns:\n",
        "            # Use the original IsHoliday, fill missing with features version\n",
        "            df['IsHoliday'] = df['IsHoliday'].fillna(df['IsHoliday_feat'])\n",
        "            df = df.drop('IsHoliday_feat', axis=1)\n",
        "\n",
        "        # Ensure IsHoliday exists and is properly formatted\n",
        "        if 'IsHoliday' in df.columns:\n",
        "            df['IsHoliday'] = df['IsHoliday'].fillna(False).astype(int)\n",
        "        else:\n",
        "            print(\"Warning: IsHoliday column not found, creating default\")\n",
        "            df['IsHoliday'] = 0\n",
        "\n",
        "        # Fill missing values efficiently\n",
        "        numeric_cols = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
        "        for col in numeric_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].fillna(df[col].median())\n",
        "                print(f\"Filled {col}: {df[col].isnull().sum()} missing values\")\n",
        "            else:\n",
        "                print(f\"Warning: {col} not found in data\")\n",
        "\n",
        "        # Markdown columns (promotional effects)\n",
        "        markdown_cols = [f'MarkDown{i}' for i in range(1, 6)]\n",
        "        for col in markdown_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].fillna(0)\n",
        "            else:\n",
        "                print(f\"Creating {col} with default values\")\n",
        "                df[col] = 0\n",
        "\n",
        "        # Store type encoding\n",
        "        if 'Type' in df.columns:\n",
        "            df['Type'] = df['Type'].fillna('A')\n",
        "            print(f\"Store types: {df['Type'].value_counts()}\")\n",
        "        else:\n",
        "            print(\"Warning: Type column not found\")\n",
        "            df['Type'] = 'A'\n",
        "\n",
        "        if 'Size' in df.columns:\n",
        "            df['Size'] = df['Size'].fillna(df['Size'].median())\n",
        "        else:\n",
        "            print(\"Warning: Size column not found\")\n",
        "            df['Size'] = 151315  # Approximate median from typical Walmart data\n",
        "\n",
        "        # Time-based features for Prophet regressors\n",
        "        df['Month'] = df['Date'].dt.month\n",
        "        df['Quarter'] = df['Date'].dt.quarter\n",
        "        df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
        "        df['Week'] = df['Date'].dt.isocalendar().week\n",
        "\n",
        "        # Seasonal indicators (key for retail)\n",
        "        df['IsQ4'] = (df['Quarter'] == 4).astype(int)  # Holiday season\n",
        "        df['IsBackToSchool'] = (df['Month'] == 8).astype(int)  # August\n",
        "        df['IsSpringCleaning'] = (df['Month'] == 4).astype(int)  # April\n",
        "        df['IsSummer'] = df['Month'].isin([6, 7, 8]).astype(int)  # Summer\n",
        "\n",
        "        # Create total markdown effect\n",
        "        df['TotalMarkDown'] = sum(df[col] for col in markdown_cols if col in df.columns)\n",
        "\n",
        "        # Economic indicators\n",
        "        if 'CPI' in df.columns and 'Unemployment' in df.columns:\n",
        "            df['EconomicIndex'] = df['CPI'] * df['Unemployment']\n",
        "        else:\n",
        "            df['EconomicIndex'] = 0\n",
        "\n",
        "        # Store size category\n",
        "        if 'Size' in df.columns:\n",
        "            df['StoreSizeCategory'] = pd.cut(df['Size'], bins=3, labels=[0, 1, 2]).astype(int)\n",
        "        else:\n",
        "            df['StoreSizeCategory'] = 1\n",
        "\n",
        "        print(f\"Final processed shape: {df.shape}\")\n",
        "        print(f\"Missing values check:\")\n",
        "        for col in ['IsHoliday', 'Temperature', 'Fuel_Price', 'TotalMarkDown']:\n",
        "            if col in df.columns:\n",
        "                print(f\"  {col}: {df[col].isnull().sum()} missing\")\n",
        "\n",
        "        return df"
      ],
      "metadata": {
        "id": "Xm2LNySnrp4G"
      },
      "id": "Xm2LNySnrp4G",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Block 3: Prophet Model for Time Series\n",
        "# =============================================================================\n",
        "\n",
        "class SuppressOutput:\n",
        "    \"\"\"Context manager to suppress Prophet output\"\"\"\n",
        "    def __enter__(self):\n",
        "        self._original_stdout = sys.stdout\n",
        "        self._original_stderr = sys.stderr\n",
        "        sys.stdout = open(os.devnull, 'w')\n",
        "        sys.stderr = open(os.devnull, 'w')\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout.close()\n",
        "        sys.stderr.close()\n",
        "        sys.stdout = self._original_stdout\n",
        "        sys.stderr = self._original_stderr\n",
        "\n",
        "class WalmartProphetModel(BaseEstimator):\n",
        "    \"\"\"Optimized Prophet model for Walmart sales forecasting\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 changepoint_prior_scale=0.05,\n",
        "                 seasonality_prior_scale=10.0,\n",
        "                 holidays_prior_scale=10.0,\n",
        "                 seasonality_mode='multiplicative',\n",
        "                 min_samples=20):\n",
        "        self.changepoint_prior_scale = changepoint_prior_scale\n",
        "        self.seasonality_prior_scale = seasonality_prior_scale\n",
        "        self.holidays_prior_scale = holidays_prior_scale\n",
        "        self.seasonality_mode = seasonality_mode\n",
        "        self.min_samples = min_samples\n",
        "        self.models = {}\n",
        "        self.global_median = None\n",
        "\n",
        "    def _create_holidays(self, df):\n",
        "        \"\"\"Create holiday dataframe for Prophet\"\"\"\n",
        "        # Create base holidays\n",
        "        base_holidays = {\n",
        "            'thanksgiving': ['2010-11-25', '2011-11-24', '2012-11-22', '2013-11-28'],\n",
        "            'christmas': ['2010-12-25', '2011-12-25', '2012-12-25', '2013-12-25'],\n",
        "            'newyear': ['2011-01-01', '2012-01-01', '2013-01-01', '2014-01-01'],\n",
        "            'superbowl': ['2011-02-06', '2012-02-05', '2013-02-03', '2014-02-02'],\n",
        "            'laborday': ['2010-09-06', '2011-09-05', '2012-09-03', '2013-09-02']\n",
        "        }\n",
        "\n",
        "        holidays_list = []\n",
        "        for holiday_name, dates in base_holidays.items():\n",
        "            for date_str in dates:\n",
        "                holidays_list.append({\n",
        "                    'holiday': holiday_name,\n",
        "                    'ds': pd.to_datetime(date_str),\n",
        "                    'lower_window': 0,\n",
        "                    'upper_window': 0\n",
        "                })\n",
        "\n",
        "        return pd.DataFrame(holidays_list)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"Fit Prophet models for each store-department combination\"\"\"\n",
        "        print(f\"Training Prophet models...\")\n",
        "\n",
        "        # Calculate global median for fallback\n",
        "        if 'Weekly_Sales' in X.columns:\n",
        "            self.global_median = X['Weekly_Sales'].median()\n",
        "        else:\n",
        "            self.global_median = 15000  # Reasonable default\n",
        "\n",
        "        # Create holidays\n",
        "        holidays = self._create_holidays(X)\n",
        "\n",
        "        # Key regressors for Prophet (only use columns that exist)\n",
        "        potential_regressors = [\n",
        "            'Temperature', 'Fuel_Price', 'IsHoliday', 'IsQ4',\n",
        "            'IsBackToSchool', 'TotalMarkDown', 'EconomicIndex', 'IsSummer'\n",
        "        ]\n",
        "\n",
        "        # Filter to only existing columns\n",
        "        regressors = [col for col in potential_regressors if col in X.columns]\n",
        "        print(f\"Using regressors: {regressors}\")\n",
        "\n",
        "        trained_count = 0\n",
        "        total_groups = len(X.groupby(['Store', 'Dept']))\n",
        "\n",
        "        for i, ((store, dept), group) in enumerate(X.groupby(['Store', 'Dept'])):\n",
        "            if i % 50 == 0:\n",
        "                print(f\"Progress: {i}/{total_groups} ({100*i/total_groups:.1f}%)\")\n",
        "\n",
        "            # Skip if insufficient data\n",
        "            if len(group) < self.min_samples:\n",
        "                continue\n",
        "\n",
        "            # Prepare data for Prophet\n",
        "            prophet_data = pd.DataFrame({\n",
        "                'ds': group['Date'],\n",
        "                'y': group['Weekly_Sales'] if 'Weekly_Sales' in group.columns else group.iloc[:, -1]  # fallback\n",
        "            })\n",
        "\n",
        "            # Add regressors\n",
        "            for regressor in regressors:\n",
        "                if regressor in group.columns:\n",
        "                    prophet_data[regressor] = group[regressor].values\n",
        "                else:\n",
        "                    prophet_data[regressor] = 0  # Default value\n",
        "\n",
        "            # Remove any remaining NaN values\n",
        "            prophet_data = prophet_data.dropna()\n",
        "\n",
        "            if len(prophet_data) < self.min_samples:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                with SuppressOutput():\n",
        "                    # Initialize Prophet model\n",
        "                    model = Prophet(\n",
        "                        changepoint_prior_scale=self.changepoint_prior_scale,\n",
        "                        seasonality_prior_scale=self.seasonality_prior_scale,\n",
        "                        holidays_prior_scale=self.holidays_prior_scale,\n",
        "                        seasonality_mode=self.seasonality_mode,\n",
        "                        holidays=holidays,\n",
        "                        daily_seasonality=False,\n",
        "                        weekly_seasonality=True,\n",
        "                        yearly_seasonality=True\n",
        "                    )\n",
        "\n",
        "                    # Add regressors\n",
        "                    for regressor in regressors:\n",
        "                        if regressor in prophet_data.columns:\n",
        "                            model.add_regressor(regressor)\n",
        "\n",
        "                    # Fit model\n",
        "                    model.fit(prophet_data)\n",
        "\n",
        "                    # Store model and info\n",
        "                    self.models[(store, dept)] = {\n",
        "                        'model': model,\n",
        "                        'regressors': regressors,\n",
        "                        'median_sales': prophet_data['y'].median()\n",
        "                    }\n",
        "                    trained_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                # Skip problematic series\n",
        "                if i < 5:  # Show first few errors for debugging\n",
        "                    print(f\"Error training model for Store {store}, Dept {dept}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"Successfully trained {trained_count} models out of {total_groups} store-dept combinations\")\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Generate predictions using trained Prophet models\"\"\"\n",
        "        predictions = []\n",
        "\n",
        "        for (store, dept), group in X.groupby(['Store', 'Dept']):\n",
        "            if (store, dept) in self.models:\n",
        "                model_info = self.models[(store, dept)]\n",
        "                model = model_info['model']\n",
        "\n",
        "                # Prepare future dataframe\n",
        "                future = pd.DataFrame({'ds': group['Date']})\n",
        "\n",
        "                # Add regressors\n",
        "                for regressor in model_info['regressors']:\n",
        "                    if regressor in group.columns:\n",
        "                        future[regressor] = group[regressor].values\n",
        "                    else:\n",
        "                        future[regressor] = 0\n",
        "\n",
        "                try:\n",
        "                    with SuppressOutput():\n",
        "                        forecast = model.predict(future)\n",
        "                    predictions.extend(forecast['yhat'].values)\n",
        "                except Exception as e:\n",
        "                    # Fallback to median\n",
        "                    median_pred = model_info['median_sales']\n",
        "                    predictions.extend([median_pred] * len(group))\n",
        "            else:\n",
        "                # Use global median for unseen store-dept combinations\n",
        "                # Apply seasonal adjustment\n",
        "                seasonal_multiplier = 1.0\n",
        "                if 'Month' in group.columns:\n",
        "                    month = group['Month'].iloc[0]\n",
        "                    if month in [11, 12]:  # Holiday season\n",
        "                        seasonal_multiplier = 1.5\n",
        "                    elif month in [1, 2]:  # Post holiday\n",
        "                        seasonal_multiplier = 0.8\n",
        "\n",
        "                pred_value = self.global_median * seasonal_multiplier\n",
        "                predictions.extend([pred_value] * len(group))\n",
        "\n",
        "        return np.array(predictions)"
      ],
      "metadata": {
        "id": "sVybN6D3rs1Y"
      },
      "id": "sVybN6D3rs1Y",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Block 4: Pipeline Training and Evaluation\n",
        "# =============================================================================\n",
        "\n",
        "# Feature engineering\n",
        "print(\"Applying feature engineering...\")\n",
        "feature_engineer = TimeSeriesFeatureEngineer()\n",
        "feature_engineer.fit(train_df)\n",
        "\n",
        "processed_train = feature_engineer.transform(train_df)\n",
        "processed_test = feature_engineer.transform(test_df)\n",
        "\n",
        "print(f\"Features added. Train shape: {processed_train.shape}\")\n",
        "\n",
        "# Time-based train/validation split\n",
        "print(\"Creating time-based validation split...\")\n",
        "max_date = processed_train['Date'].max()\n",
        "val_split_date = max_date - timedelta(weeks=8)\n",
        "\n",
        "train_data = processed_train[processed_train['Date'] <= val_split_date].copy()\n",
        "val_data = processed_train[processed_train['Date'] > val_split_date].copy()\n",
        "\n",
        "print(f\"Train: {len(train_data)} samples, Val: {len(val_data)} samples\")\n",
        "\n",
        "# Train Prophet model\n",
        "print(\"Training Prophet model...\")\n",
        "prophet_model = WalmartProphetModel(\n",
        "    changepoint_prior_scale=0.05,\n",
        "    seasonality_prior_scale=10.0,\n",
        "    seasonality_mode='multiplicative'\n",
        ")\n",
        "\n",
        "prophet_model.fit(train_data)\n",
        "\n",
        "# Validate\n",
        "print(\"Validating model...\")\n",
        "val_predictions = prophet_model.predict(val_data)\n",
        "val_mae = mean_absolute_error(val_data['Weekly_Sales'], val_predictions)\n",
        "print(f\"Validation MAE: {val_mae:.2f}\")\n",
        "\n",
        "# Log validation results\n",
        "wandb.log({\n",
        "    'validation_mae': val_mae,\n",
        "    'models_trained': len(prophet_model.models),\n",
        "    'val_samples': len(val_data)\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1shxcctsrvNL",
        "outputId": "aaf8207a-b681-45fe-8130-ef7832c55696"
      },
      "id": "1shxcctsrvNL",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying feature engineering...\n",
            "Input shape: (421570, 5)\n",
            "Input columns: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday']\n",
            "Merging with features...\n",
            "After features merge: (421570, 15)\n",
            "Merging with stores...\n",
            "After stores merge: (421570, 17)\n",
            "Columns after merge: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday_feat', 'Type', 'Size']\n",
            "Filled Temperature: 0 missing values\n",
            "Filled Fuel_Price: 0 missing values\n",
            "Filled CPI: 0 missing values\n",
            "Filled Unemployment: 0 missing values\n",
            "Store types: Type\n",
            "A    215478\n",
            "B    163495\n",
            "C     42597\n",
            "Name: count, dtype: int64\n",
            "Final processed shape: (421570, 27)\n",
            "Missing values check:\n",
            "  IsHoliday: 0 missing\n",
            "  Temperature: 0 missing\n",
            "  Fuel_Price: 0 missing\n",
            "  TotalMarkDown: 0 missing\n",
            "Input shape: (115064, 4)\n",
            "Input columns: ['Store', 'Dept', 'Date', 'IsHoliday']\n",
            "Merging with features...\n",
            "After features merge: (115064, 14)\n",
            "Merging with stores...\n",
            "After stores merge: (115064, 16)\n",
            "Columns after merge: ['Store', 'Dept', 'Date', 'IsHoliday', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday_feat', 'Type', 'Size']\n",
            "Filled Temperature: 0 missing values\n",
            "Filled Fuel_Price: 0 missing values\n",
            "Filled CPI: 0 missing values\n",
            "Filled Unemployment: 0 missing values\n",
            "Store types: Type\n",
            "A    58713\n",
            "B    44500\n",
            "C    11851\n",
            "Name: count, dtype: int64\n",
            "Final processed shape: (115064, 26)\n",
            "Missing values check:\n",
            "  IsHoliday: 0 missing\n",
            "  Temperature: 0 missing\n",
            "  Fuel_Price: 0 missing\n",
            "  TotalMarkDown: 0 missing\n",
            "Features added. Train shape: (421570, 27)\n",
            "Creating time-based validation split...\n",
            "Train: 397841 samples, Val: 23729 samples\n",
            "Training Prophet model...\n",
            "Training Prophet models...\n",
            "Using regressors: ['Temperature', 'Fuel_Price', 'IsHoliday', 'IsQ4', 'IsBackToSchool', 'TotalMarkDown', 'EconomicIndex', 'IsSummer']\n",
            "Progress: 0/3326 (0.0%)\n",
            "Progress: 50/3326 (1.5%)\n",
            "Progress: 100/3326 (3.0%)\n",
            "Progress: 150/3326 (4.5%)\n",
            "Progress: 200/3326 (6.0%)\n",
            "Progress: 250/3326 (7.5%)\n",
            "Progress: 300/3326 (9.0%)\n",
            "Progress: 350/3326 (10.5%)\n",
            "Progress: 400/3326 (12.0%)\n",
            "Progress: 450/3326 (13.5%)\n",
            "Progress: 500/3326 (15.0%)\n",
            "Progress: 550/3326 (16.5%)\n",
            "Progress: 600/3326 (18.0%)\n",
            "Progress: 650/3326 (19.5%)\n",
            "Progress: 700/3326 (21.0%)\n",
            "Progress: 750/3326 (22.5%)\n",
            "Progress: 800/3326 (24.1%)\n",
            "Progress: 850/3326 (25.6%)\n",
            "Progress: 900/3326 (27.1%)\n",
            "Progress: 950/3326 (28.6%)\n",
            "Progress: 1000/3326 (30.1%)\n",
            "Progress: 1050/3326 (31.6%)\n",
            "Progress: 1100/3326 (33.1%)\n",
            "Progress: 1150/3326 (34.6%)\n",
            "Progress: 1200/3326 (36.1%)\n",
            "Progress: 1250/3326 (37.6%)\n",
            "Progress: 1300/3326 (39.1%)\n",
            "Progress: 1350/3326 (40.6%)\n",
            "Progress: 1400/3326 (42.1%)\n",
            "Progress: 1450/3326 (43.6%)\n",
            "Progress: 1500/3326 (45.1%)\n",
            "Progress: 1550/3326 (46.6%)\n",
            "Progress: 1600/3326 (48.1%)\n",
            "Progress: 1650/3326 (49.6%)\n",
            "Progress: 1700/3326 (51.1%)\n",
            "Progress: 1750/3326 (52.6%)\n",
            "Progress: 1800/3326 (54.1%)\n",
            "Progress: 1850/3326 (55.6%)\n",
            "Progress: 1900/3326 (57.1%)\n",
            "Progress: 1950/3326 (58.6%)\n",
            "Progress: 2000/3326 (60.1%)\n",
            "Progress: 2050/3326 (61.6%)\n",
            "Progress: 2100/3326 (63.1%)\n",
            "Progress: 2150/3326 (64.6%)\n",
            "Progress: 2200/3326 (66.1%)\n",
            "Progress: 2250/3326 (67.6%)\n",
            "Progress: 2300/3326 (69.2%)\n",
            "Progress: 2350/3326 (70.7%)\n",
            "Progress: 2400/3326 (72.2%)\n",
            "Progress: 2450/3326 (73.7%)\n",
            "Progress: 2500/3326 (75.2%)\n",
            "Progress: 2550/3326 (76.7%)\n",
            "Progress: 2600/3326 (78.2%)\n",
            "Progress: 2650/3326 (79.7%)\n",
            "Progress: 2700/3326 (81.2%)\n",
            "Progress: 2750/3326 (82.7%)\n",
            "Progress: 2800/3326 (84.2%)\n",
            "Progress: 2850/3326 (85.7%)\n",
            "Progress: 2900/3326 (87.2%)\n",
            "Progress: 2950/3326 (88.7%)\n",
            "Progress: 3000/3326 (90.2%)\n",
            "Progress: 3050/3326 (91.7%)\n",
            "Progress: 3100/3326 (93.2%)\n",
            "Progress: 3150/3326 (94.7%)\n",
            "Progress: 3200/3326 (96.2%)\n",
            "Progress: 3250/3326 (97.7%)\n",
            "Progress: 3300/3326 (99.2%)\n",
            "Successfully trained 3082 models out of 3326 store-dept combinations\n",
            "Validating model...\n",
            "Validation MAE: 1897.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Block 5: Final Training and Prediction\n",
        "# =============================================================================\n",
        "\n",
        "print(\"Training final model on full dataset...\")\n",
        "final_model = WalmartProphetModel(\n",
        "    changepoint_prior_scale=0.05,\n",
        "    seasonality_prior_scale=10.0,\n",
        "    seasonality_mode='multiplicative'\n",
        ")\n",
        "\n",
        "final_model.fit(processed_train)\n",
        "\n",
        "# Generate test predictions\n",
        "print(\"Generating test predictions...\")\n",
        "test_predictions = final_model.predict(processed_test)\n",
        "\n",
        "# Basic sanity check\n",
        "print(f\"Test predictions stats:\")\n",
        "print(f\"  Mean: {np.mean(test_predictions):.2f}\")\n",
        "print(f\"  Std: {np.std(test_predictions):.2f}\")\n",
        "print(f\"  Min: {np.min(test_predictions):.2f}\")\n",
        "print(f\"  Max: {np.max(test_predictions):.2f}\")\n",
        "\n",
        "# Create submission\n",
        "submission = sample_submission.copy()\n",
        "submission['Weekly_Sales'] = test_predictions\n",
        "\n",
        "# Save results\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "submission_filename = f'prophet_submission_{timestamp}.csv'\n",
        "submission.to_csv(submission_filename, index=False)\n",
        "\n",
        "print(f\"Submission saved: {submission_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p79z3HFMrhAG",
        "outputId": "bb6b8f28-8596-4fb9-b21a-64ca31c821ab"
      },
      "id": "p79z3HFMrhAG",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training final model on full dataset...\n",
            "Training Prophet models...\n",
            "Using regressors: ['Temperature', 'Fuel_Price', 'IsHoliday', 'IsQ4', 'IsBackToSchool', 'TotalMarkDown', 'EconomicIndex', 'IsSummer']\n",
            "Progress: 0/3331 (0.0%)\n",
            "Progress: 50/3331 (1.5%)\n",
            "Progress: 100/3331 (3.0%)\n",
            "Progress: 150/3331 (4.5%)\n",
            "Progress: 200/3331 (6.0%)\n",
            "Progress: 250/3331 (7.5%)\n",
            "Progress: 300/3331 (9.0%)\n",
            "Progress: 350/3331 (10.5%)\n",
            "Progress: 400/3331 (12.0%)\n",
            "Progress: 450/3331 (13.5%)\n",
            "Progress: 500/3331 (15.0%)\n",
            "Progress: 550/3331 (16.5%)\n",
            "Progress: 600/3331 (18.0%)\n",
            "Progress: 650/3331 (19.5%)\n",
            "Progress: 700/3331 (21.0%)\n",
            "Progress: 750/3331 (22.5%)\n",
            "Progress: 800/3331 (24.0%)\n",
            "Progress: 850/3331 (25.5%)\n",
            "Progress: 900/3331 (27.0%)\n",
            "Progress: 950/3331 (28.5%)\n",
            "Progress: 1000/3331 (30.0%)\n",
            "Progress: 1050/3331 (31.5%)\n",
            "Progress: 1100/3331 (33.0%)\n",
            "Progress: 1150/3331 (34.5%)\n",
            "Progress: 1200/3331 (36.0%)\n",
            "Progress: 1250/3331 (37.5%)\n",
            "Progress: 1300/3331 (39.0%)\n",
            "Progress: 1350/3331 (40.5%)\n",
            "Progress: 1400/3331 (42.0%)\n",
            "Progress: 1450/3331 (43.5%)\n",
            "Progress: 1500/3331 (45.0%)\n",
            "Progress: 1550/3331 (46.5%)\n",
            "Progress: 1600/3331 (48.0%)\n",
            "Progress: 1650/3331 (49.5%)\n",
            "Progress: 1700/3331 (51.0%)\n",
            "Progress: 1750/3331 (52.5%)\n",
            "Progress: 1800/3331 (54.0%)\n",
            "Progress: 1850/3331 (55.5%)\n",
            "Progress: 1900/3331 (57.0%)\n",
            "Progress: 1950/3331 (58.5%)\n",
            "Progress: 2000/3331 (60.0%)\n",
            "Progress: 2050/3331 (61.5%)\n",
            "Progress: 2100/3331 (63.0%)\n",
            "Progress: 2150/3331 (64.5%)\n",
            "Progress: 2200/3331 (66.0%)\n",
            "Progress: 2250/3331 (67.5%)\n",
            "Progress: 2300/3331 (69.0%)\n",
            "Progress: 2350/3331 (70.5%)\n",
            "Progress: 2400/3331 (72.1%)\n",
            "Progress: 2450/3331 (73.6%)\n",
            "Progress: 2500/3331 (75.1%)\n",
            "Progress: 2550/3331 (76.6%)\n",
            "Progress: 2600/3331 (78.1%)\n",
            "Progress: 2650/3331 (79.6%)\n",
            "Progress: 2700/3331 (81.1%)\n",
            "Progress: 2750/3331 (82.6%)\n",
            "Progress: 2800/3331 (84.1%)\n",
            "Progress: 2850/3331 (85.6%)\n",
            "Progress: 2900/3331 (87.1%)\n",
            "Progress: 2950/3331 (88.6%)\n",
            "Progress: 3000/3331 (90.1%)\n",
            "Progress: 3050/3331 (91.6%)\n",
            "Progress: 3100/3331 (93.1%)\n",
            "Progress: 3150/3331 (94.6%)\n",
            "Progress: 3200/3331 (96.1%)\n",
            "Progress: 3250/3331 (97.6%)\n",
            "Progress: 3300/3331 (99.1%)\n",
            "Successfully trained 3087 models out of 3331 store-dept combinations\n",
            "Generating test predictions...\n",
            "Test predictions stats:\n",
            "  Mean: 15946.43\n",
            "  Std: 22678.70\n",
            "  Min: -77274.62\n",
            "  Max: 361954.49\n",
            "Submission saved: prophet_submission_20250731_003139.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Block 6: Pipeline Saving and Artifact Creation\n",
        "# =============================================================================\n",
        "\n",
        "class WalmartProphetPipeline(BaseEstimator):\n",
        "    \"\"\"Complete pipeline for Walmart sales forecasting\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.feature_engineer = TimeSeriesFeatureEngineer()\n",
        "        self.model = WalmartProphetModel()\n",
        "        self.fitted = False\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        print(\"Fitting complete pipeline...\")\n",
        "        processed_data = self.feature_engineer.fit_transform(X)\n",
        "        self.model.fit(processed_data)\n",
        "        self.fitted = True\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not self.fitted:\n",
        "            raise ValueError(\"Pipeline must be fitted before prediction\")\n",
        "        processed_data = self.feature_engineer.transform(X)\n",
        "        return self.model.predict(processed_data)\n",
        "\n",
        "# Create and save pipeline\n",
        "print(\"Creating complete pipeline...\")\n",
        "pipeline = WalmartProphetPipeline()\n",
        "pipeline.fit(train_df)\n",
        "\n",
        "# Save pipeline\n",
        "pipeline_filename = f'walmart_prophet_pipeline_{timestamp}.pkl'\n",
        "with open(pipeline_filename, 'wb') as f:\n",
        "    dill.dump(pipeline, f)\n",
        "\n",
        "print(f\"Pipeline saved: {pipeline_filename}\")\n",
        "\n",
        "# Create WandB artifacts\n",
        "pipeline_artifact = wandb.Artifact(\n",
        "    name=\"walmart_prophet_pipeline\",\n",
        "    type=\"model\",\n",
        "    description=\"Complete Prophet pipeline for Walmart sales forecasting\",\n",
        "    metadata={\n",
        "        \"model_type\": \"Prophet\",\n",
        "        \"validation_mae\": val_mae,\n",
        "        \"models_trained\": len(final_model.models),\n",
        "        \"timestamp\": timestamp\n",
        "    }\n",
        ")\n",
        "\n",
        "pipeline_artifact.add_file(pipeline_filename)\n",
        "wandb.log_artifact(pipeline_artifact)\n",
        "\n",
        "submission_artifact = wandb.Artifact(\n",
        "    name=\"walmart_prophet_submission\",\n",
        "    type=\"dataset\",\n",
        "    description=f\"Prophet submission for Walmart sales - {timestamp}\"\n",
        ")\n",
        "submission_artifact.add_file(submission_filename)\n",
        "wandb.log_artifact(submission_artifact)\n",
        "\n",
        "# Final logging\n",
        "wandb.log({\n",
        "    'pipeline_saved': True,\n",
        "    'submission_created': True,\n",
        "    'test_predictions_mean': np.mean(test_predictions),\n",
        "    'test_predictions_std': np.std(test_predictions),\n",
        "    'final_models_count': len(final_model.models)\n",
        "})\n",
        "\n",
        "print(\"Walmart Prophet forecasting completed successfully!\")\n",
        "print(f\"Validation MAE: {val_mae:.2f}\")\n",
        "print(f\"Models trained: {len(final_model.models)}\")\n",
        "print(\"Pipeline and submission saved to WandB!\")\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5WWvqh8drzoY",
        "outputId": "94238156-dfd1-4cf2-eaa7-a9bee43db616"
      },
      "id": "5WWvqh8drzoY",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating complete pipeline...\n",
            "Fitting complete pipeline...\n",
            "Input shape: (421570, 5)\n",
            "Input columns: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday']\n",
            "Merging with features...\n",
            "After features merge: (421570, 15)\n",
            "Merging with stores...\n",
            "After stores merge: (421570, 17)\n",
            "Columns after merge: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday_feat', 'Type', 'Size']\n",
            "Filled Temperature: 0 missing values\n",
            "Filled Fuel_Price: 0 missing values\n",
            "Filled CPI: 0 missing values\n",
            "Filled Unemployment: 0 missing values\n",
            "Store types: Type\n",
            "A    215478\n",
            "B    163495\n",
            "C     42597\n",
            "Name: count, dtype: int64\n",
            "Final processed shape: (421570, 27)\n",
            "Missing values check:\n",
            "  IsHoliday: 0 missing\n",
            "  Temperature: 0 missing\n",
            "  Fuel_Price: 0 missing\n",
            "  TotalMarkDown: 0 missing\n",
            "Training Prophet models...\n",
            "Using regressors: ['Temperature', 'Fuel_Price', 'IsHoliday', 'IsQ4', 'IsBackToSchool', 'TotalMarkDown', 'EconomicIndex', 'IsSummer']\n",
            "Progress: 0/3331 (0.0%)\n",
            "Progress: 50/3331 (1.5%)\n",
            "Progress: 100/3331 (3.0%)\n",
            "Progress: 150/3331 (4.5%)\n",
            "Progress: 200/3331 (6.0%)\n",
            "Progress: 250/3331 (7.5%)\n",
            "Progress: 300/3331 (9.0%)\n",
            "Progress: 350/3331 (10.5%)\n",
            "Progress: 400/3331 (12.0%)\n",
            "Progress: 450/3331 (13.5%)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2912770267.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating complete pipeline...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWalmartProphetPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Save pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2912770267.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting complete pipeline...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_engineer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3935068711.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0;31m# Fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprophet_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0;31m# Store model and info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/prophet/forecaster.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, df, **kwargs)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstan_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstan_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmcmc_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstan_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstan_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstan_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstan_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstan_fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/prophet/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, stan_init, stan_data, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstan_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;31m# Fall back on Newton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cmdstanpy/model.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, data, seed, inits, output_dir, sig_figs, save_profile, algorithm, init_alpha, tol_obj, tol_rel_obj, tol_grad, tol_rel_grad, tol_param, history_size, iter, save_iterations, require_converged, show_console, refresh, time_fmt, timeout, jacobian)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0mdummy_chain_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mrunset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_fmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_fmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             self._run_cmdstan(\n\u001b[0m\u001b[1;32m    645\u001b[0m                 \u001b[0mrunset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0mdummy_chain_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cmdstanpy/model.py\u001b[0m in \u001b[0;36m_run_cmdstan\u001b[0;34m(self, runset, idx, show_progress, show_console, progress_hook, timeout)\u001b[0m\n\u001b[1;32m   2085\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2087\u001b[0;31m                     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2088\u001b[0m                     \u001b[0mfd_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2089\u001b[0m                     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}