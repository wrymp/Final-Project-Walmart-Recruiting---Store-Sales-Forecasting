{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle wandb onnx -Uq\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leWnOYlVBGEl",
        "outputId": "74d8979c-5bb6-4540-9ec8-defae1c3ed64"
      },
      "id": "leWnOYlVBGEl",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMRWS7raBHPG",
        "outputId": "37806123-4eb9-404d-824e-da2bf13c84fb"
      },
      "id": "TMRWS7raBHPG",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‚Äò/root/.kaggle‚Äô: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Kaggle_credentials/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "7xX2rfmzBIJN"
      },
      "id": "7xX2rfmzBIJN",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "uCOxS2NxBJRV"
      },
      "id": "uCOxS2NxBJRV",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU"
      ],
      "metadata": {
        "id": "7Nk3D0umBMzJ"
      },
      "id": "7Nk3D0umBMzJ",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! kaggle competitions download -c walmart-recruiting-store-sales-forecasting"
      ],
      "metadata": {
        "id": "HEvzr6khBKUM"
      },
      "id": "HEvzr6khBKUM",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! unzip /content/walmart-recruiting-store-sales-forecasting.zip\n",
        "# ! unzip /content/train.csv.zip\n",
        "# ! unzip /content/test.csv.zip\n",
        "# ! unzip /content/features.csv.zip\n",
        "# ! unzip /content/sampleSubmission.csv.zip"
      ],
      "metadata": {
        "id": "YXsjyDYTBLfp"
      },
      "id": "YXsjyDYTBLfp",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "initial_id",
        "outputId": "659a8cf9-ef1d-4063-f0c1-83fc02dd7b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== WALMART SALES FORECASTING - MODEL INFERENCE ===\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wandb\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=== WALMART SALES FORECASTING - MODEL INFERENCE ===\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize wandb for inference\n",
        "wandb.login()\n",
        "wandb.init(project=\"walmart-sales-forecasting\", name=\"XGBoost_Inference\", tags=[\"inference\", \"xgboost\", \"submission\"])\n",
        "\n",
        "print(\"Loading test datasets...\")\n",
        "\n",
        "# Load all necessary datasets\n",
        "test = pd.read_csv(\"/content/test.csv\")\n",
        "features = pd.read_csv(\"/content/features.csv\")\n",
        "stores = pd.read_csv(\"/content/stores.csv\")\n",
        "sample_submission = pd.read_csv(\"/content/sampleSubmission.csv\")\n",
        "\n",
        "print(f\"Test data shape: {test.shape}\")\n",
        "print(f\"Features data shape: {features.shape}\")\n",
        "print(f\"Stores data shape: {stores.shape}\")\n",
        "print(f\"Sample submission shape: {sample_submission.shape}\")\n",
        "\n",
        "# Log basic info\n",
        "wandb.log({\n",
        "    \"test_samples\": test.shape[0],\n",
        "    \"submission_samples\": sample_submission.shape[0]\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "g7BTSD8e_lLg",
        "outputId": "72148451-02fd-4d7e-8b65-ba85b0236d58"
      },
      "id": "g7BTSD8e_lLg",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>merged_test_shape</td><td>‚ñÅ</td></tr><tr><td>submission_samples</td><td>‚ñÅ</td></tr><tr><td>test_missing_values</td><td>‚ñÅ</td></tr><tr><td>test_samples</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>merged_test_shape</td><td>115064</td></tr><tr><td>submission_samples</td><td>115064</td></tr><tr><td>test_date_range_end</td><td>2013-07-26 00:00:00</td></tr><tr><td>test_date_range_start</td><td>2012-11-02 00:00:00</td></tr><tr><td>test_missing_values</td><td>127817</td></tr><tr><td>test_samples</td><td>115064</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">XGBoost_Inference</strong> at: <a href='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting/runs/o1b1sn4c' target=\"_blank\">https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting/runs/o1b1sn4c</a><br> View project at: <a href='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250704_161236-o1b1sn4c/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250704_162548-075dm2h8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting/runs/075dm2h8' target=\"_blank\">XGBoost_Inference</a></strong> to <a href='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting/runs/075dm2h8' target=\"_blank\">https://wandb.ai/dshan21-free-university-of-tbilisi-/walmart-sales-forecasting/runs/075dm2h8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test datasets...\n",
            "Test data shape: (115064, 4)\n",
            "Features data shape: (8190, 12)\n",
            "Stores data shape: (45, 3)\n",
            "Sample submission shape: (115064, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge test data with features and stores (same as training process)\n",
        "print(\"\\nMerging test datasets...\")\n",
        "\n",
        "test_data = test.merge(features, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
        "test_data = test_data.merge(stores, on='Store', how='left')\n",
        "\n",
        "print(f\"Merged test data shape: {test_data.shape}\")\n",
        "print(f\"Missing values in test data:\\n{test_data.isnull().sum().sum()} total missing values\")\n",
        "\n",
        "# Check date range\n",
        "test_data['Date'] = pd.to_datetime(test_data['Date'])\n",
        "print(f\"Test date range: {test_data['Date'].min()} to {test_data['Date'].max()}\")\n",
        "\n",
        "wandb.log({\n",
        "    \"merged_test_shape\": test_data.shape[0],\n",
        "    \"test_missing_values\": test_data.isnull().sum().sum(),\n",
        "    \"test_date_range_start\": str(test_data['Date'].min()),\n",
        "    \"test_date_range_end\": str(test_data['Date'].max())\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8doMliy3JJrG",
        "outputId": "ad9ff04b-007b-4093-912a-766132532df3"
      },
      "id": "8doMliy3JJrG",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Merging test datasets...\n",
            "Merged test data shape: (115064, 15)\n",
            "Missing values in test data:\n",
            "127817 total missing values\n",
            "Test date range: 2012-11-02 00:00:00 to 2013-07-26 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the best model from wandb\n",
        "print(\"\\n=== DOWNLOADING MODEL FROM WANDB ===\")\n",
        "\n",
        "try:\n",
        "    # Get the latest version of the model artifact\n",
        "    api = wandb.Api()\n",
        "    artifact = api.artifact('walmart-sales-forecasting/xgboost_pipeline:latest', type='model')\n",
        "    artifact_dir = artifact.download()\n",
        "\n",
        "    print(f\"‚úì Model artifact downloaded to: {artifact_dir}\")\n",
        "\n",
        "    # Display model metadata\n",
        "    model_metadata = artifact.metadata\n",
        "    print(f\"\\nModel Information:\")\n",
        "    print(f\"  Training MAE: {model_metadata.get('train_mae', 'N/A')}\")\n",
        "    print(f\"  Training RMSE: {model_metadata.get('train_rmse', 'N/A')}\")\n",
        "    print(f\"  Training MAPE: {model_metadata.get('train_mape', 'N/A')}%\")\n",
        "    print(f\"  Training R¬≤: {model_metadata.get('train_r2', 'N/A')}\")\n",
        "    print(f\"  Features count: {model_metadata.get('features_count', 'N/A')}\")\n",
        "    print(f\"  Training samples: {model_metadata.get('training_samples', 'N/A')}\")\n",
        "\n",
        "    # Log model metadata\n",
        "    wandb.log({\n",
        "        \"loaded_model_mae\": model_metadata.get('train_mae', 0),\n",
        "        \"loaded_model_rmse\": model_metadata.get('train_rmse', 0),\n",
        "        \"loaded_model_r2\": model_metadata.get('train_r2', 0),\n",
        "        \"model_features\": model_metadata.get('features_count', 0)\n",
        "    })\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error downloading model: {e}\")\n",
        "    print(\"Please check your wandb project and model artifact name\")\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbIczwsLA3aT",
        "outputId": "6f301724-f5a2-4729-b1b8-178f3cf9e4ff"
      },
      "id": "NbIczwsLA3aT",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== DOWNLOADING MODEL FROM WANDB ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Model artifact downloaded to: /content/artifacts/xgboost_pipeline:v0\n",
            "\n",
            "Model Information:\n",
            "  Training MAE: 2829.0733395522316\n",
            "  Training RMSE: 4950.429855810212\n",
            "  Training MAPE: 4941.608704966984%\n",
            "  Training R¬≤: 0.9524875616202894\n",
            "  Features count: 34\n",
            "  Training samples: 421570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and load model from wandb (similar to MLflow model registry)\n",
        "print(\"\\n=== LOADING MODEL FROM WANDB ===\")\n",
        "\n",
        "with wandb.init(project=\"walmart-sales-forecasting\", name=\"Load_Best_Model\", tags=[\"inference\", \"model_loading\"]) as run:\n",
        "\n",
        "    # Download the model artifact (like MLflow model registry)\n",
        "    model_artifact_name = \"xgboost_pipeline:latest\"\n",
        "    print(f\"Loading model: {model_artifact_name}\")\n",
        "\n",
        "    try:\n",
        "        # Download artifact\n",
        "        artifact = run.use_artifact(model_artifact_name, type='model')\n",
        "        artifact_dir = artifact.download()\n",
        "\n",
        "        # Find the pipeline file\n",
        "        import os\n",
        "        pipeline_files = [f for f in os.listdir(artifact_dir) if f.endswith('.pkl')]\n",
        "        if not pipeline_files:\n",
        "            raise FileNotFoundError(\"No pipeline file found in artifact\")\n",
        "\n",
        "        pipeline_path = os.path.join(artifact_dir, pipeline_files[0])\n",
        "\n",
        "        # Load using cloudpickle (handles custom classes better) or dill\n",
        "        try:\n",
        "            import cloudpickle\n",
        "            with open(pipeline_path, 'rb') as f:\n",
        "                model_pipeline = cloudpickle.load(f)\n",
        "            print(\"‚úì Model loaded with cloudpickle\")\n",
        "        except ImportError:\n",
        "            try:\n",
        "                import dill\n",
        "                with open(pipeline_path, 'rb') as f:\n",
        "                    model_pipeline = dill.load(f)\n",
        "                print(\"‚úì Model loaded with dill\")\n",
        "            except ImportError:\n",
        "                # Install cloudpickle and retry\n",
        "                import subprocess\n",
        "                subprocess.check_call(['pip', 'install', 'cloudpickle'])\n",
        "                import cloudpickle\n",
        "                with open(pipeline_path, 'rb') as f:\n",
        "                    model_pipeline = cloudpickle.load(f)\n",
        "                print(\"‚úì Model loaded with cloudpickle (after install)\")\n",
        "\n",
        "        # Log model metadata\n",
        "        wandb.log({\n",
        "            \"model_name\": model_artifact_name,\n",
        "            \"model_loaded\": True,\n",
        "            \"pipeline_components\": list(model_pipeline.named_steps.keys())\n",
        "        })\n",
        "\n",
        "        print(f\"‚úì Model loaded successfully from wandb!\")\n",
        "        print(f\"Pipeline components: {list(model_pipeline.named_steps.keys())}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading from wandb: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "gjtzBNvVA5Cw",
        "outputId": "2f81580e-5e3e-4c21-e804-3d27947ac3a7"
      },
      "id": "gjtzBNvVA5Cw",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== LOADING MODEL PIPELINE ===\n",
            "Loading pipeline from: /content/artifacts/xgboost_pipeline:v0/xgboost_pipeline_20250704_162410.pkl\n",
            "‚ùå Error loading pipeline: Can't get attribute 'WalmartDataPreprocessor' on <module '__main__'>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Can't get attribute 'WalmartDataPreprocessor' on <module '__main__'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-23-1116184207.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Load the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodel_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úì Model pipeline loaded successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode, ensure_native_byte_order)\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0;31m# it has been written with. Other arrays are coerced to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 \u001b[0;31m# native endianness of the host system.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m                 obj = _unpickle(\n\u001b[0m\u001b[1;32m    750\u001b[0m                     \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                     \u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, ensure_native_byte_order, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             warnings.warn(\n",
            "\u001b[0;32m/usr/lib/python3.11/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pickle.py\u001b[0m in \u001b[0;36mload_stack_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"STACK_GLOBAL requires str\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1538\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTACK_GLOBAL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_stack_global\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pickle.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pickle.py\u001b[0m in \u001b[0;36m_getattribute\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             raise AttributeError(\"Can't get attribute {!r} on {!r}\"\n\u001b[0m\u001b[1;32m    332\u001b[0m                                  .format(name, obj)) from None\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'WalmartDataPreprocessor' on <module '__main__'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "print(\"\\n=== MAKING PREDICTIONS ===\")\n",
        "\n",
        "# Prepare test features (exclude target column that doesn't exist in test)\n",
        "print(\"Preparing test features...\")\n",
        "X_test = test_data.copy()\n",
        "\n",
        "print(f\"Test features shape: {X_test.shape}\")\n",
        "print(f\"Test feature columns: {list(X_test.columns)}\")\n",
        "\n",
        "# Make predictions using the pipeline\n",
        "print(\"Making predictions...\")\n",
        "test_predictions = model_pipeline.predict(X_test)\n",
        "\n",
        "print(f\"‚úì Predictions completed!\")\n",
        "print(f\"Predictions shape: {test_predictions.shape}\")\n",
        "print(f\"Predictions summary:\")\n",
        "print(f\"  Min: {test_predictions.min():.2f}\")\n",
        "print(f\"  Max: {test_predictions.max():.2f}\")\n",
        "print(f\"  Mean: {test_predictions.mean():.2f}\")\n",
        "print(f\"  Std: {test_predictions.std():.2f}\")\n",
        "\n",
        "# Log prediction statistics\n",
        "wandb.log({\n",
        "    \"predictions_count\": len(test_predictions),\n",
        "    \"predictions_min\": float(test_predictions.min()),\n",
        "    \"predictions_max\": float(test_predictions.max()),\n",
        "    \"predictions_mean\": float(test_predictions.mean()),\n",
        "    \"predictions_std\": float(test_predictions.std())\n",
        "})"
      ],
      "metadata": {
        "id": "s7K6SWSrJR49"
      },
      "id": "s7K6SWSrJR49",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create submission file\n",
        "print(\"\\n=== CREATING SUBMISSION FILE ===\")\n",
        "\n",
        "# Create submission DataFrame\n",
        "submission = sample_submission.copy()\n",
        "submission['Weekly_Sales'] = test_predictions\n",
        "\n",
        "# Verify submission format\n",
        "print(f\"Submission shape: {submission.shape}\")\n",
        "print(f\"Submission columns: {list(submission.columns)}\")\n",
        "print(\"\\nFirst 10 predictions:\")\n",
        "print(submission.head(10))\n",
        "\n",
        "print(\"\\nLast 10 predictions:\")\n",
        "print(submission.tail(10))\n",
        "\n",
        "# Check for any issues\n",
        "if submission.isnull().sum().sum() > 0:\n",
        "    print(f\"‚ö†Ô∏è  Warning: {submission.isnull().sum().sum()} missing values in submission\")\n",
        "else:\n",
        "    print(\"‚úì No missing values in submission\")\n",
        "\n",
        "if len(submission) != len(sample_submission):\n",
        "    print(f\"‚ö†Ô∏è  Warning: Submission length mismatch!\")\n",
        "    print(f\"Expected: {len(sample_submission)}, Got: {len(submission)}\")\n",
        "else:\n",
        "    print(\"‚úì Submission length matches expected format\")"
      ],
      "metadata": {
        "id": "up9_RoxMA8vB"
      },
      "id": "up9_RoxMA8vB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save submission file\n",
        "print(\"\\n=== SAVING SUBMISSION ===\")\n",
        "\n",
        "# Create timestamped filename\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "submission_filename = f\"xgboost_submission_{timestamp}.csv\"\n",
        "\n",
        "# Save submission\n",
        "submission.to_csv(submission_filename, index=False)\n",
        "print(f\"‚úì Submission saved as: {submission_filename}\")\n",
        "\n",
        "# Display submission statistics\n",
        "print(f\"\\nSubmission Statistics:\")\n",
        "print(f\"  Total predictions: {len(submission):,}\")\n",
        "print(f\"  Average prediction: ${submission['Weekly_Sales'].mean():,.2f}\")\n",
        "print(f\"  Prediction range: ${submission['Weekly_Sales'].min():,.2f} - ${submission['Weekly_Sales'].max():,.2f}\")\n",
        "\n",
        "# Create simple visualization of predictions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(test_predictions, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "plt.xlabel('Predicted Weekly Sales')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Predictions')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(test_predictions[:1000])  # Plot first 1000 predictions\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Predicted Weekly Sales')\n",
        "plt.title('First 1000 Predictions')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('prediction_analysis.png', dpi=300, bbox_inches='tight')\n",
        "wandb.log({\"prediction_analysis\": wandb.Image('prediction_analysis.png')})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9DErV-oeA-Jy"
      },
      "id": "9DErV-oeA-Jy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log submission as wandb artifact\n",
        "print(\"\\n=== LOGGING SUBMISSION TO WANDB ===\")\n",
        "\n",
        "try:\n",
        "    # Create submission artifact\n",
        "    submission_artifact = wandb.Artifact(\n",
        "        name=f\"submission_{timestamp}\",\n",
        "        type=\"submission\",\n",
        "        description=f\"XGBoost submission for Walmart sales forecasting - {timestamp}\",\n",
        "        metadata={\n",
        "            \"submission_count\": len(submission),\n",
        "            \"predictions_mean\": float(submission['Weekly_Sales'].mean()),\n",
        "            \"predictions_std\": float(submission['Weekly_Sales'].std()),\n",
        "            \"predictions_min\": float(submission['Weekly_Sales'].min()),\n",
        "            \"predictions_max\": float(submission['Weekly_Sales'].max()),\n",
        "            \"model_used\": \"XGBoost Pipeline\",\n",
        "            \"timestamp\": timestamp\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Add submission file to artifact\n",
        "    submission_artifact.add_file(submission_filename)\n",
        "\n",
        "    # Log artifact\n",
        "    wandb.log_artifact(submission_artifact)\n",
        "    print(\"‚úì Submission logged to wandb successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Error logging submission to wandb: {e}\")\n",
        "    print(\"Submission file saved locally\")\n",
        "\n",
        "# Final log\n",
        "wandb.log({\n",
        "    \"submission_filename\": submission_filename,\n",
        "    \"inference_completed\": True,\n",
        "    \"final_submission_count\": len(submission)\n",
        "})"
      ],
      "metadata": {
        "id": "9IWshmUtM8zy"
      },
      "id": "9IWshmUtM8zy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final summary and instructions\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(\"INFERENCE COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"üìÅ Submission file: {submission_filename}\")\n",
        "print(f\"üìä Total predictions: {len(submission):,}\")\n",
        "print(f\"üí∞ Average prediction: ${submission['Weekly_Sales'].mean():,.2f}\")\n",
        "print(f\"üìà Prediction range: ${submission['Weekly_Sales'].min():,.2f} - ${submission['Weekly_Sales'].max():,.2f}\")\n",
        "print(f\"ü§ñ Model used: XGBoost Pipeline\")\n",
        "print(f\"‚è∞ Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"=\"*70)\n",
        "print(\"üì§ NEXT STEPS:\")\n",
        "print(f\"1. Upload '{submission_filename}' to Kaggle competition\")\n",
        "print(\"2. Check your score on the leaderboard\")\n",
        "print(\"3. Compare with other models\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "sgUrCfrhM-Vi"
      },
      "id": "sgUrCfrhM-Vi",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}